# -*- coding: utf-8 -*-
"""knn preporecss ALisa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yVPcOJ_31UKE-QA_BFzwInyReDl_iaqW
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import PolynomialFeatures
from sklearn import linear_model
import statsmodels.api as sm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
import warnings
from warnings import filterwarnings

warnings.filterwarnings("ignore", category=DeprecationWarning)
filterwarnings('ignore')
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV

df = pd.read_csv('hospital_deaths_train.csv')


# todo: delete this file
selected_feat = ['Age', 'Albumin_first', 'Albumin_last', 'BUN_last', 'Bilirubin_last',
                 'CCU', 'CSRU', 'FiO2_first', 'FiO2_last', 'GCS_highest', 'GCS_last',
                 'GCS_lowest', 'GCS_median', 'Glucose_last', 'HCO3_last', 'HR_highest',
                 'HR_last', 'HR_median', 'Lactate_last', 'MechVentLast8Hour',
                 'MechVentStartTime', 'NIDiasABP_lowest', 'NIDiasABP_median',
                 'NISysABP_last', 'PaCO2_first', 'PaO2_first', 'SICU', 'Temp_first',
                 'Temp_last', 'Temp_lowest', 'Temp_median', 'WBC_last', 'Weight']


def preprocess_data(df):
    # drop columns with 60% nulls
    a = (df.isnull().sum() / df.shape[0] * 100).sort_values(ascending=False)
    col_to_drop = a[(a) > 60].keys()
    output_df = df.drop(col_to_drop, axis=1)

    # fill missing values with medians
    median_dict = output_df.median()
    for col in output_df.columns:
        median_value = median_dict[col]
        output_df[col].fillna(median_value, inplace=True)

    # splitting data
    xTrain, xTest, yTrain, yTest = train_test_split(output_df[output_df.columns.difference(['In-hospital_death'])],
                                                    output_df['In-hospital_death'], test_size=0.2, random_state=10,
                                                    stratify=output_df['In-hospital_death'])

    # scaling
    scaler = MinMaxScaler().fit(xTrain[xTrain.columns])
    xTrain[xTrain.columns] = scaler.transform(xTrain[xTrain.columns])
    xTest[xTest.columns] = scaler.transform(xTest[xTest.columns])

    xTrain = xTrain[selected_feat]
    xTest = xTest[selected_feat]

    return xTrain, xTest, yTrain, yTest


xTrain = preprocess_data(df)[0]
xTest = preprocess_data(df)[1]
yTrain = preprocess_data(df)[2]
yTest = preprocess_data(df)[3]

# def diff(xTrain , XTest)
#     # here I overcome the problem when initial columns and structure of test dataset would be the same as the train dataset,
#     feature_difference = set(selected_feat) - set(XTest.columns())
#     # selected_feat list I got as a result of feature selection , I dont know how to use to it in this function.
#     feature_difference_df = pd.DataFrame(data=np.zeros((xTrain.shape[0], len(feature_difference))),
#                                      columns=list(feature_difference))
#     test = XTest.join(feature_difference_df)
#     for column in test.columns:
#         if column not in selected_feat:
#             test.drop([column], axis=1, inplace=True)
#     test = test.reindex(sorted(test.columns), axis=1)
#     return test

knn = KNeighborsClassifier()
param_grid = {'n_neighbors': [1, 2, 3, 5, 7, 10, 15, 20, 25, 30], 'weights': ['uniform', 'distance']}

# Perform Grid Search with cross-validation
grid_search = GridSearchCV(knn, param_grid, cv=5)
grid_search.fit(xTrain, yTrain)

# Get best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

# Train the model with best parameters
best_k = best_params['n_neighbors']
best_weights = best_params['weights']
knn_best = KNeighborsClassifier(n_neighbors=best_k, weights=best_weights)
knn_best.fit(xTrain, yTrain)

# Make predictions
y_pred = knn_best.predict(xTest)

# Calculate accuracy
accuracy = accuracy_score(yTest, y_pred)
print('Accuracy:', accuracy)

print(best_params)
